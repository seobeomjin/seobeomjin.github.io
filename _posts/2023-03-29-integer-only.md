---
layout: post
title: 2018 CVPR, Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference 
subtitle: Efficient Integer-Arithmetic-Only Inference ë…¼ë¬¸ ë¦¬ë·° ë‚´ìš©ì˜ í›„ê¸°ë¥¼ ì ì–´ë´…ë‹ˆë‹¤.
categories: Paper-review  
tags: quantization inference data-type
comments: True
published: False
---


## Introduction 
- ë…¼ë¬¸ì˜ ì œì•ˆ
    - weight ì™€ activation ëª¨ë‘ int-quantizationí•´ì„œ inference time ì— integer ì—°ì‚°ë§Œ í™œìš©í•˜ê² ë‹¤. 
    (opinion. 23ë…„ ê¸°ì¤€ì˜ ë‹¤ë¥¸ PTQ ì•Œê³ ë¦¬ì¦˜ë“¤ì—ì„œì˜ integer quantì˜ ê¸°ë²•ë“¤ë„ ì´ëŸ° ì‘ìš©ì„ ê±°ì¹˜ëŠ” ê²ƒì¸ê°€?ğŸ’¥)
- Activation ì´ë€?
    Inference timeì— inputì— ë”°ë¼ ê°’ì´ ë³€í•˜ëŠ” variable   
- Low Precicion benefits 
    ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš© / ë¹ ë¥¸ ì»´í“¨í…Œì´ì…˜ ì†ë„ / ì „ë ¥ ì†Œë¹„ ê°ì†Œ / AI accelerators í™œìš© ê°€ëŠ¥ 

## Quantized Inference
- Quantization Scheme 
    - ì‹¤ìˆ˜ rì„ ì–´ë–¤ ì •ìˆ˜ qì— mapping ì‹œí‚¬ ê²ƒì¸ê°€? ë¥¼ ê³ ë¯¼í•˜ëŠ” ë¬¸ì œ 
    - r = S(q-Z)     
    - S 
        = scaling factor 
        = (rmax-rmin) / 2^N such that N is number of quantization bit
    - Z = -round(rmin/S)
    - S,ZëŠ” ì‹¤ìˆ˜ ë²”ìœ„ì— ë”°ë¼ ì •í•´ì§€ëŠ” quantization parameter 
    - ê° layerì˜ arrayì— ì¡´ì¬í•˜ëŠ” ì‹¤ìˆ˜ Rê³¼ ì •ìˆ˜ Q ì‚¬ì´ì˜ S,Z ê°’ì€ ê³µìœ   

- Matrix Multiplication 
    - Example 
        r3 = r1 * r2 matmul ì—°ì‚°ì´ ìˆìŒ. 
        S3(q3-Z3) = S1(q1-Z1) * S2(q2-Z2) ì¼ ë•Œ, q1,q2ë¥¼ ì•Œë©´ q3ì„ êµ¬í•  ìˆ˜ ìˆì„ê¹Œ? 

- Typical Fused Layer 


## Training with Simulated Quantization 
- motivation 
    - common approach 
        - 
        -
    - common approach ëŠ” small model ì—ì„œ ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤ 
        - 
        -
    - ë”°ë¼ì„œ quantization effect ë¥¼ training timeì˜ forward pass ì— ì ìš©í•´ ë³´ê³ ì í•œë‹¤.

## Experiments

    