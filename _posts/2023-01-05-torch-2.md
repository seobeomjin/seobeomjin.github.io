---
layout: post
title: Pytorch 이모저모 (2) 
subtitle: Pytorch 언어를 사용하며 배운 내용들을 정리합니다. (2)
categories: Study
tags: pytorch framework
comments: True
published: True
---

- nn.Module.register_buffer <br>
    optimize 나 grad update 가 없고, tesnor를 저장해서 활용하는 용도 
- torch.tril <br>
    lower triangular matrix 

- torch.split(tensor, split_size, dim) <br>

- torch.view <br>
    기존의 tensor를 원하는 view size 에 맞춰서 resize하여 return 해줌. 

- a @ b.transpose(-1, -2) <br>
    - a matrix 와 b matrix 사이의 matmul 
    - transpose(-1,-2) 는 -1 dim 과 -2 dim을 transpose <br>
        따라서 transpose(1,2) == transpose(2,1) , transpose(-1,-2) == transpose(-2, -1) 

- tensor.masked_fill(self.bias[:,:,:T,:T]==0, float('-inf')) <br>

- F.softmax(att, dim=-1) <br>

- nn.Dropout(p=0.5) <br>

- contiguous() <br>
    transpose(), view(), expand(), narrow() 등의 tensor 조작 작업을 하게 되면, tensor들의 메모리 저장상태가 변경되는 경우들이 많다. <br>
    이 때 contiguous()를 통해 메모리 저장 순서를 axis=0을 기준으로 정렬(?)해주는 함수이다. <br>


### Reference 
